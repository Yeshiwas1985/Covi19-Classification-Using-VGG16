{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SGhzT1OI4Xuu",
    "outputId": "d35897d4-4f0f-4577-8484-265e2d646faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dvYKI1nt5lWE",
    "outputId": "c294a593-ebed-4d40-e0a1-517125a3c557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/MyDrive\n"
     ]
    }
   ],
   "source": [
    "%cd /content/gdrive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YlgsrpCz6DS5"
   },
   "outputs": [],
   "source": [
    "# VGG16 is a popular deep convolutional neural network architecture used in computer vision.\n",
    "# Developed by the Visual Geometry Group at the University of Oxford, it is named after its 16 weight layers.\n",
    "\n",
    "# Key characteristics of VGG16 include:\n",
    "# 1. Depth: VGG16 comprises 16 layers, making it a deep network with 13 convolutional layers and 3 fully connected layers.\n",
    "# 2. Small Convolutional Kernels: It uses 3x3 convolutional kernels, which are effective for capturing local features.\n",
    "# 3. Max-Pooling Layers: VGG16 incorporates max-pooling layers after each pair of convolutional layers for downsampling.\n",
    "# 4. Fully Connected Layers: The last three layers are fully connected, providing class probabilities for classification tasks.\n",
    "# 5. ReLU Activation: Rectified Linear Unit (ReLU) activation functions introduce non-linearity.\n",
    "# 6. Dropout: Dropout layers are used to reduce overfitting during training.\n",
    "\n",
    "# VGG16 was highly successful in image classification, particularly in the 2014 ImageNet Challenge.\n",
    "# It is still used in various computer vision applications, such as transfer learning, object recognition, and feature extraction.\n",
    "# However, its depth and parameter count make it resource-intensive in terms of computational and memory requirements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MtzCmDTl6DV3"
   },
   "source": [
    "### 1. Importing Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "JTZtKm8q7hqX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-45ez4m27lYv"
   },
   "source": [
    "### 2. Import the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "G43MLXmH7luF"
   },
   "outputs": [],
   "source": [
    "# Define the directory path for the training data.\n",
    "train_dir = \"/content/gdrive/MyDrive/Covid_19 Classification/Covid19-dataset/train/\"\n",
    "\n",
    "# Define the directory path for the testing data.\n",
    "test_dir = \"/content/gdrive/MyDrive/Covid_19 Classification/Covid19-dataset/test/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DWBKgToA7lyI"
   },
   "outputs": [],
   "source": [
    "# Define the categories (classes) your model will classify data into.\n",
    "categories = ['Covid', 'Normal', 'Viral Pneumonia']\n",
    "\n",
    "# Initialize empty lists for storing your data and labels.\n",
    "y = []  # Combined labels\n",
    "x = []  # Combined data\n",
    "\n",
    "# Set the batch size for training your model. Batch size determines how many data samples are processed in each iteration.\n",
    "Batch_Size = 32\n",
    "\n",
    "# Set the initial learning rate for your model. Learning rate affects the step size in training algorithms.\n",
    "INIT_LR = 1e-4\n",
    "\n",
    "# Define the number of epochs. An epoch is one complete pass through the entire training dataset.\n",
    "EPOCHES = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0p3LQiDe7l1e"
   },
   "source": [
    "### 3. Reading Images from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOh-V1MX7l4r"
   },
   "source": [
    "#### 3.1 Reading The Images From The Train Dataset and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwcfVYDb7-k6",
    "outputId": "f437bcc1-de59-47de-d9db-a949dc7e026a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1806\n",
      "1375\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Import the OpenCV library.\n",
    "import cv2\n",
    "\n",
    "# Read an image from the specified file path.\n",
    "im = cv2.imread('/content/gdrive/MyDrive/Covid_19 Classification/Covid19-dataset/train/Covid/COVID-00013b.jpg')\n",
    "\n",
    "# Get the dimensions of the image: width (w), height (h), and number of color channels (c).\n",
    "h, w, c = im.shape\n",
    "\n",
    "# Print the width of the image.\n",
    "print(w)\n",
    "\n",
    "# Print the height of the image.\n",
    "print(h)\n",
    "\n",
    "# Print the number of color channels (e.g., 3 for RGB images).\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yeVbV1nR7-nz"
   },
   "outputs": [],
   "source": [
    "# Loop through the defined categories (e.g., 'Covid', 'Normal', 'Viral Pneumonia').\n",
    "for category in categories:\n",
    "    # Create the full path to the directory for the current category within the training directory.\n",
    "    path = os.path.join(train_dir, category)\n",
    "\n",
    "    # Iterate through the files in the current category directory.\n",
    "    for img in os.listdir(path):\n",
    "        # Create the full path to the current image file.\n",
    "        img_path = os.path.join(path, img)\n",
    "\n",
    "        # Read the image using OpenCV.\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        # Resize the image to a common size (e.g., 500x500 pixels).\n",
    "        image = cv2.resize(image, (500, 500))\n",
    "\n",
    "        # Normalize the image pixel values to be in the range [0, 1].\n",
    "        image = image / 255.0\n",
    "\n",
    "        # Append the preprocessed image to the data list (x).\n",
    "        x.append(image)\n",
    "\n",
    "        # Append the corresponding category label to the labels list (y).\n",
    "        y.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40uFYjsW7-rS",
    "outputId": "1190c7c9-67ff-486e-bfb6-f4f4bcbb385e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.03529412, 0.03529412, 0.03529412],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        ...,\n",
       "        [0.05098039, 0.05098039, 0.05098039],\n",
       "        [0.05882353, 0.05882353, 0.05882353],\n",
       "        [0.05098039, 0.05098039, 0.05098039]],\n",
       "\n",
       "       [[0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.02745098, 0.02745098, 0.02745098],\n",
       "        [0.02745098, 0.02745098, 0.02745098],\n",
       "        ...,\n",
       "        [0.03529412, 0.03529412, 0.03529412],\n",
       "        [0.05098039, 0.05098039, 0.05098039],\n",
       "        [0.05490196, 0.05490196, 0.05490196]],\n",
       "\n",
       "       [[0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.02352941, 0.02352941, 0.02352941],\n",
       "        ...,\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03529412, 0.03529412, 0.03529412],\n",
       "        [0.05098039, 0.05098039, 0.05098039]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.02745098, 0.02745098, 0.02745098],\n",
       "        [0.02745098, 0.02745098, 0.02745098],\n",
       "        [0.02745098, 0.02745098, 0.02745098]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NULFz_vG7-zE",
    "outputId": "585892f8-cdfa-4f13-dd73-c5b48fc67b74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Covid', 'Covid', 'Covid', 'Covid', 'Covid']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgIaoS8X7_CU"
   },
   "source": [
    "#### 3.1. Reading The Images From The Test Dataset and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KBR-QSCQrmuG"
   },
   "outputs": [],
   "source": [
    "# Loop through the defined categories (e.g., 'Covid', 'Normal', 'Viral Pneumonia').\n",
    "for category in categories:\n",
    "    # Create the full path to the directory for the current category within the testing directory.\n",
    "    path = os.path.join(test_dir, category)\n",
    "\n",
    "    # Iterate through the files in the current category directory.\n",
    "    for img in os.listdir(path):\n",
    "        # Create the full path to the current image file.\n",
    "        img_path = os.path.join(path, img)\n",
    "\n",
    "        # Read the image using OpenCV.\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        # Resize the image to a common size (e.g., 500x500 pixels).\n",
    "        image = cv2.resize(image, (500, 500))\n",
    "\n",
    "        # Normalize the image pixel values to be in the range [0, 1].\n",
    "        image = image / 255.0\n",
    "\n",
    "        # Append the preprocessed image to the data list (x).\n",
    "        x.append(image)\n",
    "\n",
    "        # Append the corresponding category label to the labels list (y).\n",
    "        y.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "INdo49yjrmw6",
    "outputId": "2f13dbb5-e711-43c5-d699-e819f4815a9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.03529412, 0.03529412, 0.03529412],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        ...,\n",
       "        [0.05098039, 0.05098039, 0.05098039],\n",
       "        [0.05882353, 0.05882353, 0.05882353],\n",
       "        [0.05098039, 0.05098039, 0.05098039]],\n",
       "\n",
       "       [[0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.02745098, 0.02745098, 0.02745098],\n",
       "        [0.02745098, 0.02745098, 0.02745098],\n",
       "        ...,\n",
       "        [0.03529412, 0.03529412, 0.03529412],\n",
       "        [0.05098039, 0.05098039, 0.05098039],\n",
       "        [0.05490196, 0.05490196, 0.05490196]],\n",
       "\n",
       "       [[0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.02352941, 0.02352941, 0.02352941],\n",
       "        ...,\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03529412, 0.03529412, 0.03529412],\n",
       "        [0.05098039, 0.05098039, 0.05098039]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.02745098, 0.02745098, 0.02745098],\n",
       "        [0.02745098, 0.02745098, 0.02745098],\n",
       "        [0.02745098, 0.02745098, 0.02745098]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CPtC3P4BrmzT",
    "outputId": "accc4909-b940-42d8-8280-58a92047275c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Covid', 'Covid', 'Covid', 'Covid', 'Covid']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1svRhzwjrm2F"
   },
   "source": [
    "### 4. Preprocessing The Data And Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MFwftBOprm7p"
   },
   "outputs": [],
   "source": [
    "# Import the train_test_split function from scikit-learn to split the data.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets:\n",
    "# - x is the data (images).\n",
    "# - y is the labels (categories).\n",
    "# - test_size specifies the proportion of the data to be used for testing (e.g., 20%).\n",
    "# - random_state is used for reproducibility of the split.\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# After this code, you'll have:\n",
    "# - x_train: Training data (images).\n",
    "# - x_test: Testing data (images).\n",
    "# - y_train: Training labels (categories).\n",
    "# - y_test: Testing labels (categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oWtY7-FIrm-o"
   },
   "outputs": [],
   "source": [
    "# perform one-hot encoding on the class labels. \n",
    "# One-hot encoding is a common technique used in machine learning for handling categorical labels. \n",
    "# It transforms categorical labels into a binary format that is suitable for use in machine learning models.\n",
    "\n",
    "# Initialize a LabelBinarizer object.\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "# Fit and transform the training labels (y_train) to one-hot encoded format.\n",
    "y_train = lb.fit_transform(y_train)\n",
    "\n",
    "# Transform the testing labels (y_test) to one-hot encoded format using the same LabelBinarizer.\n",
    "y_test = lb.transform(y_test)\n",
    "\n",
    "# After this code, y_train and y_test will be one-hot encoded, where each category is represented as a binary vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tzgw5xsJr-eX"
   },
   "outputs": [],
   "source": [
    "#### convert your data and labels to NumPy arrays and specifying the data type as 'float32'.\n",
    "#### This data type is often used in machine learning for numerical computations and is more memory-efficient compared to other data types like 'float64'\n",
    "\n",
    "x_train = np.array(x_train,dtype='float32')\n",
    "y_train = np.array(y_train,dtype='float32')\n",
    "x_test = np.array(x_test,dtype='float32')\n",
    "y_test = np.array(y_test,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gh-Mshcrr-g3",
    "outputId": "e1ea5bf4-8483-4302-bac0-b02340c175ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 500, 500, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJEBSLQdsGJg",
    "outputId": "bfa38d02-17ef-4628-bd09-c2e7df3a6030"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "etFjWp4usGMf",
    "outputId": "bbd013d1-807e-45e3-9fdc-df4401cbe197"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 500, 500, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KU4mrZlusGO0",
    "outputId": "9a0eeb00-b82d-4d3f-f1e9-755322e588d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oo_rWpXWsGRh"
   },
   "source": [
    "### 5. Bulding A VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xpur5D02r-lW",
    "outputId": "b407460a-c191-479f-8df6-34b833a608d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "#### Using VGG16\n",
    "\n",
    "# Load the pre-trained VGG16 model without the top classification layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(500, 500, 3))\n",
    "\n",
    "# Freeze the convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new classification head\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(3, activation='softmax')(x)  # Adjust the number of units for your task (3 for your case)\n",
    "\n",
    "# Create the fine-tuned model\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model with an appropriate optimizer and loss function\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oLv3qG1VvJXq",
    "outputId": "97804361-39f3-4f54-a4e6-fef4fef24a2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 500, 500, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 500, 500, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 500, 500, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 250, 250, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 250, 250, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 250, 250, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 125, 125, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 125, 125, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 125, 125, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 125, 125, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 62, 62, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 62, 62, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 62, 62, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 62, 62, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 31, 31, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 31, 31, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 31, 31, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 31, 31, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 15, 15, 512)       0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 115200)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               14745728  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29460803 (112.38 MB)\n",
      "Trainable params: 14746115 (56.25 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpJLuipYr-oJ"
   },
   "source": [
    "### 6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1sc7SaTsX4Y",
    "outputId": "f9b92550-7b9f-4033-cb59-86c06efafe35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 8s 957ms/step - loss: 0.2823 - accuracy: 0.8933 - val_loss: 0.0617 - val_accuracy: 0.9844\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 7s 956ms/step - loss: 0.2471 - accuracy: 0.9130 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 8s 992ms/step - loss: 0.2999 - accuracy: 0.8814 - val_loss: 0.0424 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2248 - accuracy: 0.9328 - val_loss: 0.0486 - val_accuracy: 0.9844\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2815 - accuracy: 0.9091 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2691 - accuracy: 0.9249 - val_loss: 0.0606 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 8s 975ms/step - loss: 0.2290 - accuracy: 0.9289 - val_loss: 0.1037 - val_accuracy: 0.9531\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 7s 963ms/step - loss: 0.1859 - accuracy: 0.9407 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2646 - accuracy: 0.9091 - val_loss: 0.0398 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 7s 941ms/step - loss: 0.2157 - accuracy: 0.9249 - val_loss: 0.0464 - val_accuracy: 0.9844\n",
      "2/2 [==============================] - 2s 749ms/step - loss: 0.0464 - accuracy: 0.9844\n",
      "Test Loss: 0.04638753458857536\n",
      "Test Accuracy: 0.984375\n"
     ]
    }
   ],
   "source": [
    "# Train the model with your data\n",
    "model.fit(x_train, y_train, epochs=EPOCHES, batch_size=Batch_Size, validation_data=(x_test, y_test))\n",
    "\n",
    "# After training, you can evaluate the model and save it\n",
    "evaluation = model.evaluate(x_test, y_test, batch_size=Batch_Size)\n",
    "print(\"Test Loss:\", evaluation[0])\n",
    "print(\"Test Accuracy:\", evaluation[1])\n",
    "\n",
    "# Save the model\n",
    "model.save(\"Covid_VGG16.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47Q8FVIOsX-C"
   },
   "source": [
    "### 7. Evaluate the model using new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzYVorsRsYEo",
    "outputId": "7ac0245e-099b-412a-9bfd-39072ddc355a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted Class: Covid\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the new image\n",
    "new_image_path = '/content/gdrive/MyDrive/Covid_19 Classification/Covid19-dataset/train/Covid/COVID-00013b.jpg'  # Replace with the path to your new image\n",
    "new_image = cv2.imread(new_image_path)\n",
    "new_image = cv2.resize(new_image, (500, 500))\n",
    "new_image = new_image / 255  # Normalize pixel values\n",
    "\n",
    "# Expand dimensions to match the model's input shape\n",
    "new_image = np.expand_dims(new_image, axis=0)\n",
    "\n",
    "# Use the model to make predictions\n",
    "predictions = model.predict(new_image)\n",
    "\n",
    "# Interpret the predictions\n",
    "class_index = np.argmax(predictions)  # Get the index of the class with the highest probability\n",
    "predicted_class = categories[class_index]  # Map the index to the class label\n",
    "\n",
    "# Print the predicted class\n",
    "print(\"Predicted Class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfIzR6W8sYXM"
   },
   "source": [
    "### 8. Evaluate the saved model in new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zo6yf8gAsYaK",
    "outputId": "ac096723-443c-4849-ed27-adbbbd8a0848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 139ms/step\n",
      "Predicted Class: Normal\n"
     ]
    }
   ],
   "source": [
    "### Testing a model with another new image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model(\"/content/gdrive/MyDrive/Covid_19 Classification/Covid_VGG16.h5\")\n",
    "\n",
    "# Preprocess a new image\n",
    "new_image_path1 = \"/content/gdrive/MyDrive/Covid_19 Classification/Covid19-dataset/test/Normal/0101.jpeg\"  # Replace with the path to your new image\n",
    "new_image1 = cv2.imread(new_image_path1)\n",
    "new_image1 = cv2.resize(new_image1, (500, 500))\n",
    "new_image1 = new_image1 / 255  # Normalize pixel values\n",
    "new_image1 = np.expand_dims(new_image1, axis=0)  # Expand dimensions\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "predictions = loaded_model.predict(new_image1)\n",
    "\n",
    "# Interpret the predictions (e.g., get the predicted class label)\n",
    "class_index = np.argmax(predictions)\n",
    "predicted_class = categories[class_index]\n",
    "print(\"Predicted Class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wl-jCVfZ4V5l"
   },
   "source": [
    "### 9. Visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "id": "Gh0RoBsx4R89",
    "outputId": "4a7e059a-6dd6-4cd3-bbd3-09e4eea4f889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66 images belonging to 3 classes.\n",
      "66/66 [==============================] - 3s 38ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Covid       1.00      1.00      1.00        26\n",
      "         Normal       1.00      1.00      1.00        20\n",
      "Viral Pneumonia       1.00      1.00      1.00        20\n",
      "\n",
      "       accuracy                           1.00        66\n",
      "      macro avg       1.00      1.00      1.00        66\n",
      "   weighted avg       1.00      1.00      1.00        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create a data generator for the test set\n",
    "test_data_generator = ImageDataGenerator(rescale=1.0/255.0)  # Rescale pixel values\n",
    "\n",
    "# Load the test data from the directories\n",
    "test_data = test_data_generator.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(500, 500),  # Adjust target size as needed\n",
    "    batch_size=1,  # Set batch size to 1 to visualize individual predictions\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Important to match predictions with true labels\n",
    ")\n",
    "\n",
    "# Get true labels\n",
    "true_labels = test_data.classes\n",
    "\n",
    "# Predict using your VGG16 model\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Generate a confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions.argmax(axis=1))\n",
    "\n",
    "# Get class names (categories)\n",
    "class_names = list(test_data.class_indices.keys())\n",
    "\n",
    "# Display the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(true_labels, predictions.argmax(axis=1), target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1w8suxIWsYdA"
   },
   "source": [
    "### .... Finished ...."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
